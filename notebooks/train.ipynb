{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faster RCNN Installation\n",
    "* In production, we want to install the custom faster rcnn without cloning the whole source repository. This is an example of how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://adamj.eu/tech/2019/03/11/pip-install-from-a-git-repository/\n",
    "# Install customized linc-detector faster-rcnn\n",
    "# !pip install --upgrade --force-reinstall git+https://github.com/linc-lion/LINC-detector.git@ba36a5bfa5ba7b9035977c02b1d8ed253f074e8d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Directory\n",
    "* The jupyter notebook is in the same repository as the source. So, we are switching to the parent directory as working directory so that imports work.\n",
    "* Do the following only for local development. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sglee/work/git/linc/LINC-detector'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get parent directory\n",
    "if 'parent_dir' not in globals():\n",
    "    import os\n",
    "    current_dir = os.getcwd()\n",
    "    parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sglee/work/git/linc/LINC-detector\n"
     ]
    }
   ],
   "source": [
    "cd $parent_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pycocotools\n",
    "!pip install --upgrade --force-reinstall cython\n",
    "!pip install --upgrade --force-reinstall -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "!pip install setuptools==59.5.0 # https://github.com/pytorch/pytorch/issues/69894"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from linc.detector.models import detection\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from linc.detector.helper.coco_utils import get_coco  # get_coco_kp\n",
    "from linc.detector.helper.group_by_aspect_ratio import GroupedBatchSampler, create_aspect_ratio_groups\n",
    "from linc.detector.helper.engine import train_one_epoch, evaluate\n",
    "from linc.detector.helper import utils\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "* The base training code is extracted from [pytorch example](https://github.com/pytorch/vision/blob/528651a031a08f9f97cc75bd619a326387708219/references/detection/train.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to COCO formatted object detection dataset\n",
    "data_path = 'datasets/coco_all_but_ws_and_fb/'  \n",
    "\n",
    "# Ignorable arguments\n",
    "epochs = 2 # 35\n",
    "save_every_num_epochs = None  # Optional\n",
    "evaluate_every_num_epochs = 2\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "lr_steps = [10, 11]\n",
    "lr_gamma = 0.1\n",
    "batch_size = 3\n",
    "workers = 8\n",
    "run_name = \"linc-detector-tensorboard\"  # Optional, str used to name Tensorboard summaries\n",
    "num_draw_predictions = 5\n",
    "draw_threshold = 0.5\n",
    "aspect_ratio_group_factor = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create summary writer for Tensorboard\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Summary folder 'linc-detector-tensorboard' already exists. Overwrite it [yes, y / no, n]? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 15:48:28.543090: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create datasets\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Categorizing into 32 classes\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Create samplers\n",
      "Using [0, 1.0, inf] as bins for aspect ratio quantization\n",
      "Count of instances per bin: [15  1]\n",
      "Create dataloaders\n",
      "Create model\n",
      "Device: cpu\n",
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sglee/anaconda3/envs/linc-detector-jupyter/lib/python3.8/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n",
      "/Users/sglee/anaconda3/envs/linc-detector-jupyter/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [0/5]  eta: 0:03:35  lr: 0.002507  loss: 4.1980 (4.1980)  loss_classifier: 3.4123 (3.4123)  loss_box_reg: 0.0358 (0.0358)  loss_objectness: 0.6914 (0.6914)  loss_rpn_box_reg: 0.0585 (0.0585)  time: 43.1151  data: 4.1610  max mem: 0\n",
      "Epoch: [0]  [4/5]  eta: 0:00:39  lr: 0.010000  loss: 3.9909 (3.4164)  loss_classifier: 3.1898 (2.6101)  loss_box_reg: 0.0358 (0.0372)  loss_objectness: 0.6883 (0.6789)  loss_rpn_box_reg: 0.0658 (0.0902)  time: 39.5915  data: 0.8670  max mem: 0\n",
      "Epoch: [0] Total time: 0:03:42 (44.5942 s / it)\n",
      "Epoch time 223.00907802581787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  [0/5]  eta: 0:00:37  model_time: 5.2197 (5.2197)  evaluator_time: 0.0019 (0.0019)  time: 7.4111  data: 2.1890  max mem: 0\n",
      "Test:  [4/5]  eta: 0:00:05  model_time: 5.0308 (5.0758)  evaluator_time: 0.0007 (0.0009)  time: 5.5330  data: 0.4382  max mem: 0\n",
      "Test: Total time: 0:00:52 (10.5353 s / it)\n",
      "Averaged stats: model_time: 5.0308 (5.0758)  evaluator_time: 0.0007 (0.0009)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Epoch: [1]  [0/5]  eta: 0:04:00  lr: 0.010000  loss: 1.2643 (1.2643)  loss_classifier: 0.6733 (0.6733)  loss_box_reg: 0.0638 (0.0638)  loss_objectness: 0.4212 (0.4212)  loss_rpn_box_reg: 0.1061 (0.1061)  time: 48.1383  data: 4.0683  max mem: 0\n",
      "Epoch: [1]  [4/5]  eta: 0:00:42  lr: 0.010000  loss: 1.2463 (1.0858)  loss_classifier: 0.5412 (0.5555)  loss_box_reg: 0.0638 (0.0646)  loss_objectness: 0.3350 (0.3700)  loss_rpn_box_reg: 0.0802 (0.0957)  time: 42.3636  data: 0.8407  max mem: 0\n",
      "Epoch: [1] Total time: 0:03:56 (47.3663 s / it)\n",
      "Epoch time 236.90256595611572\n",
      "Training time 0:08:32\n"
     ]
    }
   ],
   "source": [
    "# Training code is based on \n",
    "\n",
    "print(\"Create summary writer for Tensorboard\")\n",
    "if run_name:\n",
    "    log_dir_path = f\"{run_name}\" if run_name else None\n",
    "    if os.path.isdir(log_dir_path):\n",
    "        delete = input(f\"Summary folder '{log_dir_path}' already exists. Overwrite it [yes, y / no, n]?\")\n",
    "        if delete in ('yes', 'y'):\n",
    "            shutil.rmtree(log_dir_path)\n",
    "        else:\n",
    "            print(f\"Chose another run name or delete the folder then!\")\n",
    "            exit()\n",
    "else:\n",
    "    log_dir_path = None\n",
    "writer = SummaryWriter(log_dir=log_dir_path)\n",
    "\n",
    "# Add some useful text summaries (Tensorboard uses markdown to render text).\n",
    "# writer.add_text('Command executed', f\"python {' '.join(sys.argv)}\")\n",
    "# writer.add_text('Arguments', str(args).replace(\", \", \",  \\n\").replace(\"Namespace(\", \"\").replace(\")\", \"\"))\n",
    "\n",
    "print(\"Create datasets\")\n",
    "dataset, num_classes, label_names = get_coco(data_path, image_set='train')\n",
    "print(f\"Categorizing into {num_classes} classes\")\n",
    "dataset_test, _, _ = get_coco(data_path, image_set='val')\n",
    "\n",
    "print(\"Create samplers\")\n",
    "train_sampler = torch.utils.data.RandomSampler(dataset)\n",
    "test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "group_ids = create_aspect_ratio_groups(dataset, k=aspect_ratio_group_factor)\n",
    "train_batch_sampler = GroupedBatchSampler(train_sampler, group_ids, batch_size)\n",
    "\n",
    "print(\"Create dataloaders\")\n",
    "data_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                          batch_sampler=train_batch_sampler, \n",
    "                                          num_workers=workers, \n",
    "                                          collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, \n",
    "                                               batch_size=1,\n",
    "                                               sampler=test_sampler, \n",
    "                                               num_workers=workers, \n",
    "                                               collate_fn=utils.collate_fn)\n",
    "\n",
    "print(\"Create model\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "model = detection.__dict__['fasterrcnn_resnet50_fpn'](num_classes=num_classes, pretrained=False)\n",
    "model.to(device)\n",
    "model_without_ddp = model\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, \n",
    "                            lr=lr, \n",
    "                            momentum=momentum, \n",
    "                            weight_decay=weight_decay)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                                    milestones=lr_steps, \n",
    "                                                    gamma=lr_gamma)\n",
    "\n",
    "print(\"Start training\")\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    start_epoch = time.time()\n",
    "    train_one_epoch(\n",
    "        model, optimizer, data_loader, device, epoch, 20, writer, label_names\n",
    "    )\n",
    "    print(f\"Epoch time {time.time() - start_epoch}\")\n",
    "    writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if save_every_num_epochs and epoch % save_every_num_epochs == 0:\n",
    "        utils.save_on_master({\n",
    "            'model': model_without_ddp.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'args': args,\n",
    "            'label_names': label_names},\n",
    "            os.path.join(writer.log_dir, 'model_{}.pth'.format(epoch))\n",
    "        )\n",
    "\n",
    "    if epoch % evaluate_every_num_epochs == 0:\n",
    "        evaluate(\n",
    "            model, data_loader_test, epoch, writer, draw_threshold,\n",
    "            label_names, num_draw_predictions, device=device\n",
    "        )\n",
    "\n",
    "# Save after training is done\n",
    "utils.save_on_master({\n",
    "    'model': model_without_ddp.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'lr_scheduler': lr_scheduler.state_dict(),\n",
    "    'label_names': label_names},\n",
    "    os.path.join(writer.log_dir, 'model_finished.pth')\n",
    ")\n",
    "\n",
    "writer.close()\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print('Training time {}'.format(total_time_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b06c5442c74e3b64\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b06c5442c74e3b64\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir linc-detector-tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
