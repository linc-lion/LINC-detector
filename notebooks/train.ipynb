{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo training code\n",
    "\n",
    "This is a simplified version of the training code to be used as a demo. The more complete version, with more options, is in the `train.py` cli script. Checkpoints and tensorboard summaries are saved in `notebooks/runs/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to COCO formatted object detection dataset\n",
    "data_path = '../data/all_but_ws_and_fb_fixed/'  \n",
    "\n",
    "# Ignorable arguments\n",
    "epochs = 35\n",
    "save_every_num_epochs = None  # Optional\n",
    "evaluate_every_num_epochs = 2\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "lr_steps = [10, 11]\n",
    "lr_gamma = 0.1\n",
    "batch_size = 3\n",
    "workers = 8\n",
    "run_name = None  # Optional, str used to name Tensorboard summaries\n",
    "num_draw_predictions = 5\n",
    "draw_threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebooks are stored in 'notebooks/' which breaks my imports\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from models import detection\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from coco_utils import get_coco  # get_coco_kp\n",
    "\n",
    "from group_by_aspect_ratio import GroupedBatchSampler, create_aspect_ratio_groups\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary writer for Tensorboard\n",
    "if run_name:\n",
    "    log_dir_path = f\"runs/{run_name}\" if run_name else None\n",
    "    if os.path.isdir(log_dir_path):\n",
    "        delete = input(f\"Summary folder '{log_dir_path}' already exists. Overwrite it [yes, y / no, n]?\")\n",
    "        if delete in ('yes', 'y'):\n",
    "            shutil.rmtree(log_dir_path)\n",
    "        else:\n",
    "            print(f\"Chose another run name or delete the folder then!\")\n",
    "            exit()\n",
    "else:\n",
    "    log_dir_path = None\n",
    "writer = SummaryWriter(log_dir=log_dir_path)\n",
    "\n",
    "# Create datasets\n",
    "dataset, num_classes, label_names = get_coco(data_path, image_set='train')\n",
    "print(f\"Categorizing into {num_classes} classes\")\n",
    "dataset_test, _, _ = get_coco(data_path, image_set='val')\n",
    "\n",
    "# Create samplers\n",
    "train_sampler = torch.utils.data.RandomSampler(dataset)\n",
    "test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "group_ids = create_aspect_ratio_groups(dataset)\n",
    "train_batch_sampler = GroupedBatchSampler(train_sampler, group_ids, batch_size)\n",
    "\n",
    "# Create dataloaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_sampler=train_batch_sampler, num_workers=workers,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1,\n",
    "    sampler=test_sampler, num_workers=workers,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "# Create model\n",
    "device = torch.device('cuda' if torch.has_cuda else 'cpu')\n",
    "model = detection.fasterrcnn_resnet50_fpn(num_classes=num_classes, pretrained=False)\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=lr_steps, gamma=lr_gamma\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"Start training\")\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    start_epoch = time.time()\n",
    "    train_one_epoch(\n",
    "        model, optimizer, data_loader, device, epoch, 20, writer, label_names\n",
    "    )\n",
    "    print(f\"Epoch time {time.time() - start_epoch}\")\n",
    "    writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if save_every_num_epochs and epoch % save_every_num_epochs == 0:\n",
    "        utils.save_on_master({\n",
    "            'model': model_without_ddp.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'label_names': label_names},\n",
    "            os.path.join(writer.log_dir, 'model_{}.pth'.format(epoch))\n",
    "        )\n",
    "\n",
    "    if epoch % evaluate_every_num_epochs == 0:\n",
    "        evaluate(\n",
    "            model, data_loader_test, epoch, writer, draw_threshold,\n",
    "            label_names, num_draw_predictions, device=device\n",
    "        )\n",
    "\n",
    "# Save final checkpoint after training is done\n",
    "utils.save_on_master({\n",
    "    'model': model_without_ddp.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'lr_scheduler': lr_scheduler.state_dict(),\n",
    "    'label_names': label_names},\n",
    "    os.path.join(writer.log_dir, 'model_finished.pth')\n",
    ")\n",
    "\n",
    "writer.close()\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print('Training time {}'.format(total_time_str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
