{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/linc-lion/LINC-detector.git@0856b965862ac7b16535e91cec827726110e7f45\n",
      "  Cloning https://github.com/linc-lion/LINC-detector.git (to revision 0856b965862ac7b16535e91cec827726110e7f45) to /private/var/folders/gj/d1dhz4yj7qg61hcmnsqs8mhc0000gn/T/pip-req-build-ittqduub\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/linc-lion/LINC-detector.git /private/var/folders/gj/d1dhz4yj7qg61hcmnsqs8mhc0000gn/T/pip-req-build-ittqduub\n",
      "  Running command git rev-parse -q --verify 'sha^0856b965862ac7b16535e91cec827726110e7f45'\n",
      "  Running command git fetch -q https://github.com/linc-lion/LINC-detector.git 0856b965862ac7b16535e91cec827726110e7f45\n",
      "  Running command git checkout -q 0856b965862ac7b16535e91cec827726110e7f45\n",
      "  Resolved https://github.com/linc-lion/LINC-detector.git to commit 0856b965862ac7b16535e91cec827726110e7f45\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow==2.10.0\n",
      "  Using cached tensorflow-2.10.0-cp38-cp38-macosx_10_14_x86_64.whl (241.2 MB)\n",
      "Collecting numpy==1.23.3\n",
      "  Using cached numpy-1.23.3-cp38-cp38-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "Collecting torchvision==0.5.0\n",
      "  Using cached torchvision-0.5.0-cp38-cp38-macosx_10_9_x86_64.whl (438 kB)\n",
      "Collecting future==0.17.1\n",
      "  Using cached future-0.17.1-py3-none-any.whl\n",
      "Collecting six>=1.12.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.27.0-cp38-cp38-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.48.1-cp38-cp38-macosx_10_10_x86_64.whl (4.5 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.4-cp38-cp38-macosx_10_9_x86_64.whl (961 kB)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Using cached tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-65.3.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-macosx_10_9_x86_64.whl (13.2 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.0.0-py3-none-any.whl (5.4 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp38-cp38-macosx_10_9_x86_64.whl (35 kB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.7.0-cp38-cp38-macosx_10_9_x86_64.whl (3.2 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting torch==1.4.0\n",
      "  Using cached torch-1.4.0-cp38-none-macosx_10_9_x86_64.whl (81.2 MB)\n",
      "Collecting pillow>=4.1.1\n",
      "  Using cached Pillow-9.2.0-cp38-cp38-macosx_10_10_x86_64.whl (3.1 MB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.11.0-py2.py3-none-any.whl (167 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.6.15.1-py3-none-any.whl (160 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-2.1.1-cp38-cp38-macosx_10_9_x86_64.whl (13 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: linc-detector\n",
      "  Building wheel for linc-detector (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for linc-detector: filename=linc_detector-0.2.dev0-py3-none-any.whl size=57880 sha256=834a28df2b93af21b4efc7ee1141f4c3fb0210bc0510573616ab9b39b08da151\n",
      "  Stored in directory: /Users/sglee/Library/Caches/pip/wheels/5e/dd/e8/597c3f92c14df31ced1d34815905bc719ec3a48aafa860e7f8\n",
      "Successfully built linc-detector\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, zipp, wrapt, wheel, urllib3, typing-extensions, torch, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, rsa, pyparsing, pyasn1-modules, protobuf, pillow, oauthlib, numpy, MarkupSafe, idna, gast, future, charset-normalizer, certifi, cachetools, absl-py, werkzeug, torchvision, requests, packaging, opt-einsum, keras-preprocessing, importlib-metadata, h5py, grpcio, google-pasta, google-auth, astunparse, requests-oauthlib, markdown, google-auth-oauthlib, tensorboard, tensorflow, linc-detector\n",
      "  Attempting uninstall: tensorboard-plugin-wit\n",
      "    Found existing installation: tensorboard-plugin-wit 1.8.1\n",
      "    Uninstalling tensorboard-plugin-wit-1.8.1:\n",
      "      Successfully uninstalled tensorboard-plugin-wit-1.8.1\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.4.8\n",
      "    Uninstalling pyasn1-0.4.8:\n",
      "      Successfully uninstalled pyasn1-0.4.8\n",
      "  Attempting uninstall: libclang\n",
      "    Found existing installation: libclang 14.0.6\n",
      "    Uninstalling libclang-14.0.6:\n",
      "      Successfully uninstalled libclang-14.0.6\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.10.0\n",
      "    Uninstalling keras-2.10.0:\n",
      "      Successfully uninstalled keras-2.10.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 2.0.7\n",
      "    Uninstalling flatbuffers-2.0.7:\n",
      "      Successfully uninstalled flatbuffers-2.0.7\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.8.1\n",
      "    Uninstalling zipp-3.8.1:\n",
      "      Successfully uninstalled zipp-3.8.1\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.14.1\n",
      "    Uninstalling wrapt-1.14.1:\n",
      "      Successfully uninstalled wrapt-1.14.1\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.37.1\n",
      "    Uninstalling wheel-0.37.1:\n",
      "      Successfully uninstalled wheel-0.37.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.12\n",
      "    Uninstalling urllib3-1.26.12:\n",
      "      Successfully uninstalled urllib3-1.26.12\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 2.0.0\n",
      "    Uninstalling termcolor-2.0.0:\n",
      "      Successfully uninstalled termcolor-2.0.0\n",
      "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
      "    Found existing installation: tensorflow-io-gcs-filesystem 0.27.0\n",
      "    Uninstalling tensorflow-io-gcs-filesystem-0.27.0:\n",
      "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.27.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.10.0\n",
      "    Uninstalling tensorflow-estimator-2.10.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.10.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.3.0\n",
      "    Uninstalling setuptools-65.3.0:\n",
      "      Successfully uninstalled setuptools-65.3.0\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.9\n",
      "    Uninstalling rsa-4.9:\n",
      "      Successfully uninstalled rsa-4.9\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: pyasn1-modules\n",
      "    Found existing installation: pyasn1-modules 0.2.8\n",
      "    Uninstalling pyasn1-modules-0.2.8:\n",
      "      Successfully uninstalled pyasn1-modules-0.2.8\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.4\n",
      "    Uninstalling protobuf-3.19.4:\n",
      "      Successfully uninstalled protobuf-3.19.4\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.2.0\n",
      "    Uninstalling Pillow-9.2.0:\n",
      "      Successfully uninstalled Pillow-9.2.0\n",
      "  Attempting uninstall: oauthlib\n",
      "    Found existing installation: oauthlib 3.2.1\n",
      "    Uninstalling oauthlib-3.2.1:\n",
      "      Successfully uninstalled oauthlib-3.2.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.3\n",
      "    Uninstalling numpy-1.23.3:\n",
      "      Successfully uninstalled numpy-1.23.3\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.1\n",
      "    Uninstalling MarkupSafe-2.1.1:\n",
      "      Successfully uninstalled MarkupSafe-2.1.1\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.3\n",
      "    Uninstalling idna-3.3:\n",
      "      Successfully uninstalled idna-3.3\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Attempting uninstall: future\n",
      "    Found existing installation: future 0.17.1\n",
      "    Uninstalling future-0.17.1:\n",
      "      Successfully uninstalled future-0.17.1\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.1.1\n",
      "    Uninstalling charset-normalizer-2.1.1:\n",
      "      Successfully uninstalled charset-normalizer-2.1.1\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.6.15.1\n",
      "    Uninstalling certifi-2022.6.15.1:\n",
      "      Successfully uninstalled certifi-2022.6.15.1\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 5.2.0\n",
      "    Uninstalling cachetools-5.2.0:\n",
      "      Successfully uninstalled cachetools-5.2.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.2.0\n",
      "    Uninstalling absl-py-1.2.0:\n",
      "      Successfully uninstalled absl-py-1.2.0\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 2.2.2\n",
      "    Uninstalling Werkzeug-2.2.2:\n",
      "      Successfully uninstalled Werkzeug-2.2.2\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.5.0\n",
      "    Uninstalling torchvision-0.5.0:\n",
      "      Successfully uninstalled torchvision-0.5.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 3.3.0\n",
      "    Uninstalling opt-einsum-3.3.0:\n",
      "      Successfully uninstalled opt-einsum-3.3.0\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.2\n",
      "    Uninstalling Keras-Preprocessing-1.1.2:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.12.0\n",
      "    Uninstalling importlib-metadata-4.12.0:\n",
      "      Successfully uninstalled importlib-metadata-4.12.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.7.0\n",
      "    Uninstalling h5py-3.7.0:\n",
      "      Successfully uninstalled h5py-3.7.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.48.1\n",
      "    Uninstalling grpcio-1.48.1:\n",
      "      Successfully uninstalled grpcio-1.48.1\n",
      "  Attempting uninstall: google-pasta\n",
      "    Found existing installation: google-pasta 0.2.0\n",
      "    Uninstalling google-pasta-0.2.0:\n",
      "      Successfully uninstalled google-pasta-0.2.0\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.11.0\n",
      "    Uninstalling google-auth-2.11.0:\n",
      "      Successfully uninstalled google-auth-2.11.0\n",
      "  Attempting uninstall: astunparse\n",
      "    Found existing installation: astunparse 1.6.3\n",
      "    Uninstalling astunparse-1.6.3:\n",
      "      Successfully uninstalled astunparse-1.6.3\n",
      "  Attempting uninstall: requests-oauthlib\n",
      "    Found existing installation: requests-oauthlib 1.3.1\n",
      "    Uninstalling requests-oauthlib-1.3.1:\n",
      "      Successfully uninstalled requests-oauthlib-1.3.1\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.4.1\n",
      "    Uninstalling Markdown-3.4.1:\n",
      "      Successfully uninstalled Markdown-3.4.1\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.6\n",
      "    Uninstalling google-auth-oauthlib-0.4.6:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.10.0\n",
      "    Uninstalling tensorboard-2.10.0:\n",
      "      Successfully uninstalled tensorboard-2.10.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.10.0\n",
      "    Uninstalling tensorflow-2.10.0:\n",
      "      Successfully uninstalled tensorflow-2.10.0\n",
      "  Attempting uninstall: linc-detector\n",
      "    Found existing installation: linc-detector 0.2.dev0\n",
      "    Uninstalling linc-detector-0.2.dev0:\n",
      "      Successfully uninstalled linc-detector-0.2.dev0\n",
      "Successfully installed MarkupSafe-2.1.1 absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 certifi-2022.6.15.1 charset-normalizer-2.1.1 flatbuffers-2.0.7 future-0.17.1 gast-0.4.0 google-auth-2.11.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.48.1 h5py-3.7.0 idna-3.3 importlib-metadata-4.12.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 linc-detector-0.2.dev0 markdown-3.4.1 numpy-1.23.3 oauthlib-3.2.1 opt-einsum-3.3.0 packaging-21.3 pillow-9.2.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 setuptools-65.3.0 six-1.16.0 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.0 torch-1.4.0 torchvision-0.5.0 typing-extensions-4.3.0 urllib3-1.26.12 werkzeug-2.2.2 wheel-0.37.1 wrapt-1.14.1 zipp-3.8.1\n"
     ]
    }
   ],
   "source": [
    "# https://adamj.eu/tech/2019/03/11/pip-install-from-a-git-repository/\n",
    "# Install customized linc-detector faster-rcnn\n",
    "!pip install --upgrade --force-reinstall git+https://github.com/linc-lion/LINC-detector.git@0856b965862ac7b16535e91cec827726110e7f45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cython\n",
      "  Using cached Cython-0.29.32-py2.py3-none-any.whl (986 kB)\n",
      "Installing collected packages: cython\n",
      "  Attempting uninstall: cython\n",
      "    Found existing installation: Cython 0.29.32\n",
      "    Uninstalling Cython-0.29.32:\n",
      "      Successfully uninstalled Cython-0.29.32\n",
      "Successfully installed cython-0.29.32\n",
      "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
      "  Cloning https://github.com/cocodataset/cocoapi.git to /private/var/folders/gj/d1dhz4yj7qg61hcmnsqs8mhc0000gn/T/pip-req-build-rr6djite\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /private/var/folders/gj/d1dhz4yj7qg61hcmnsqs8mhc0000gn/T/pip-req-build-rr6djite\n",
      "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setuptools>=18.0\n",
      "  Using cached setuptools-65.3.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting cython>=0.27.3\n",
      "  Using cached Cython-0.29.32-py2.py3-none-any.whl (986 kB)\n",
      "Collecting matplotlib>=2.1.0\n",
      "  Using cached matplotlib-3.5.3-cp38-cp38-macosx_10_9_x86_64.whl (7.3 MB)\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp38-cp38-macosx_10_9_x86_64.whl (65 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.2.0-cp38-cp38-macosx_10_10_x86_64.whl (3.1 MB)\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-1.23.3-cp38-cp38-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.37.1-py3-none-any.whl (957 kB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting python-dateutil>=2.7\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0-cp38-cp38-macosx_10_9_x86_64.whl size=89610 sha256=d2e75f2ed3cc5a6f47c71778a603bf72cc6cc59af65923bdd1ba3a72cb39e13b\n",
      "  Stored in directory: /private/var/folders/gj/d1dhz4yj7qg61hcmnsqs8mhc0000gn/T/pip-ephem-wheel-cache-hki8qwxx/wheels/56/da/49/cb71a7c450b59588934077f431100c05fbde50646ee84a8d40\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: six, setuptools, pyparsing, pillow, numpy, kiwisolver, fonttools, cython, cycler, python-dateutil, packaging, matplotlib, pycocotools\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.3.0\n",
      "    Uninstalling setuptools-65.3.0:\n",
      "      Successfully uninstalled setuptools-65.3.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.2.0\n",
      "    Uninstalling Pillow-9.2.0:\n",
      "      Successfully uninstalled Pillow-9.2.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.3\n",
      "    Uninstalling numpy-1.23.3:\n",
      "      Successfully uninstalled numpy-1.23.3\n",
      "  Attempting uninstall: kiwisolver\n",
      "    Found existing installation: kiwisolver 1.4.4\n",
      "    Uninstalling kiwisolver-1.4.4:\n",
      "      Successfully uninstalled kiwisolver-1.4.4\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.37.1\n",
      "    Uninstalling fonttools-4.37.1:\n",
      "      Successfully uninstalled fonttools-4.37.1\n",
      "  Attempting uninstall: cython\n",
      "    Found existing installation: Cython 0.29.32\n",
      "    Uninstalling Cython-0.29.32:\n",
      "      Successfully uninstalled Cython-0.29.32\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.11.0\n",
      "    Uninstalling cycler-0.11.0:\n",
      "      Successfully uninstalled cycler-0.11.0\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.5.3\n",
      "    Uninstalling matplotlib-3.5.3:\n",
      "      Successfully uninstalled matplotlib-3.5.3\n",
      "  Attempting uninstall: pycocotools\n",
      "    Found existing installation: pycocotools 2.0\n",
      "    Uninstalling pycocotools-2.0:\n",
      "      Successfully uninstalled pycocotools-2.0\n",
      "Successfully installed cycler-0.11.0 cython-0.29.32 fonttools-4.37.1 kiwisolver-1.4.4 matplotlib-3.5.3 numpy-1.23.3 packaging-21.3 pillow-9.2.0 pycocotools-2.0 pyparsing-3.0.9 python-dateutil-2.8.2 setuptools-65.3.0 six-1.16.0\n"
     ]
    }
   ],
   "source": [
    "# Install pycocotools\n",
    "!pip install --upgrade --force-reinstall cython\n",
    "!pip install --upgrade --force-reinstall -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from linc.detector.models import detection\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from linc.detector.helper.coco_utils import get_coco  # get_coco_kp\n",
    "from linc.detector.helper.group_by_aspect_ratio import GroupedBatchSampler, create_aspect_ratio_groups\n",
    "from linc.detector.helper.engine import train_one_epoch, evaluate\n",
    "from linc.detector.helper import utils\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "* The base training code is extracted from [pytorch example](https://github.com/pytorch/vision/blob/528651a031a08f9f97cc75bd619a326387708219/references/detection/train.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to COCO formatted object detection dataset\n",
    "data_path = '../datasets/coco_all_but_ws_and_fb/'  \n",
    "\n",
    "# Ignorable arguments\n",
    "epochs = 2 # 35\n",
    "save_every_num_epochs = None  # Optional\n",
    "evaluate_every_num_epochs = 2\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "lr_steps = [10, 11]\n",
    "lr_gamma = 0.1\n",
    "batch_size = 3\n",
    "workers = 8\n",
    "run_name = \"linc-detector-tensorboard\"  # Optional, str used to name Tensorboard summaries\n",
    "num_draw_predictions = 5\n",
    "draw_threshold = 0.5\n",
    "aspect_ratio_group_factor = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create summary writer for Tensorboard\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Summary folder 'linc-detector-tensorboard' already exists. Overwrite it [yes, y / no, n]? yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-11 12:27:06.642054: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create datasets\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Categorizing into 32 classes\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Create samplers\n",
      "Using [0, 1.0, inf] as bins for aspect ratio quantization\n",
      "Count of instances per bin: [15  1]\n",
      "Create dataloaders\n",
      "Create model\n",
      "Device: cpu\n",
      "Start training\n",
      "Epoch: [0]  [0/5]  eta: 0:03:52  lr: 0.002507  loss: 4.2483 (4.2483)  loss_classifier: 3.4470 (3.4470)  loss_box_reg: 0.0203 (0.0203)  loss_objectness: 0.6902 (0.6902)  loss_rpn_box_reg: 0.0908 (0.0908)  time: 46.4494  data: 3.5685  max mem: 0\n",
      "Epoch: [0]  [4/5]  eta: 0:00:40  lr: 0.010000  loss: 4.1892 (4.1375)  loss_classifier: 3.4133 (3.3396)  loss_box_reg: 0.0203 (0.0224)  loss_objectness: 0.6896 (0.6885)  loss_rpn_box_reg: 0.0908 (0.0870)  time: 40.4812  data: 0.7419  max mem: 0\n",
      "Epoch: [0] Total time: 0:03:22 (40.5414 s / it)\n",
      "Epoch time 202.76696014404297\n",
      "Test:  [0/5]  eta: 0:00:36  model_time: 5.4164 (5.4164)  evaluator_time: 0.0019 (0.0019)  time: 7.2819  data: 1.8635  max mem: 0\n",
      "Test:  [4/5]  eta: 0:00:05  model_time: 4.8651 (4.9764)  evaluator_time: 0.0006 (0.0009)  time: 5.3633  data: 0.3731  max mem: 0\n",
      "Test: Total time: 0:00:27 (5.4216 s / it)\n",
      "Averaged stats: model_time: 4.8651 (4.9764)  evaluator_time: 0.0006 (0.0009)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Epoch: [1]  [0/5]  eta: 0:03:42  lr: 0.010000  loss: 3.2722 (3.2722)  loss_classifier: 2.5291 (2.5291)  loss_box_reg: 0.0160 (0.0160)  loss_objectness: 0.6713 (0.6713)  loss_rpn_box_reg: 0.0558 (0.0558)  time: 44.5704  data: 2.7262  max mem: 0\n",
      "Epoch: [1]  [4/5]  eta: 0:01:15  lr: 0.010000  loss: 1.4353 (1.6925)  loss_classifier: 0.6411 (1.0195)  loss_box_reg: 0.0554 (0.0637)  loss_objectness: 0.5020 (0.5162)  loss_rpn_box_reg: 0.1073 (0.0930)  time: 75.8183  data: 0.5765  max mem: 0\n",
      "Epoch: [1] Total time: 0:06:19 (75.8881 s / it)\n",
      "Epoch time 379.5007789134979\n",
      "Training time 0:10:09\n"
     ]
    }
   ],
   "source": [
    "# Training code is based on \n",
    "\n",
    "print(\"Create summary writer for Tensorboard\")\n",
    "if run_name:\n",
    "    log_dir_path = f\"{run_name}\" if run_name else None\n",
    "    if os.path.isdir(log_dir_path):\n",
    "        delete = input(f\"Summary folder '{log_dir_path}' already exists. Overwrite it [yes, y / no, n]?\")\n",
    "        if delete in ('yes', 'y'):\n",
    "            shutil.rmtree(log_dir_path)\n",
    "        else:\n",
    "            print(f\"Chose another run name or delete the folder then!\")\n",
    "            exit()\n",
    "else:\n",
    "    log_dir_path = None\n",
    "writer = SummaryWriter(log_dir=log_dir_path)\n",
    "\n",
    "# Add some useful text summaries (Tensorboard uses markdown to render text).\n",
    "# writer.add_text('Command executed', f\"python {' '.join(sys.argv)}\")\n",
    "# writer.add_text('Arguments', str(args).replace(\", \", \",  \\n\").replace(\"Namespace(\", \"\").replace(\")\", \"\"))\n",
    "\n",
    "print(\"Create datasets\")\n",
    "dataset, num_classes, label_names = get_coco(data_path, image_set='train')\n",
    "print(f\"Categorizing into {num_classes} classes\")\n",
    "dataset_test, _, _ = get_coco(data_path, image_set='val')\n",
    "\n",
    "print(\"Create samplers\")\n",
    "train_sampler = torch.utils.data.RandomSampler(dataset)\n",
    "test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "group_ids = create_aspect_ratio_groups(dataset, k=aspect_ratio_group_factor)\n",
    "train_batch_sampler = GroupedBatchSampler(train_sampler, group_ids, batch_size)\n",
    "\n",
    "print(\"Create dataloaders\")\n",
    "data_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                          batch_sampler=train_batch_sampler, \n",
    "                                          num_workers=workers, \n",
    "                                          collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, \n",
    "                                               batch_size=1,\n",
    "                                               sampler=test_sampler, \n",
    "                                               num_workers=workers, \n",
    "                                               collate_fn=utils.collate_fn)\n",
    "\n",
    "print(\"Create model\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "model = detection.__dict__['fasterrcnn_resnet50_fpn'](num_classes=num_classes, pretrained=False)\n",
    "model.to(device)\n",
    "model_without_ddp = model\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, \n",
    "                            lr=lr, \n",
    "                            momentum=momentum, \n",
    "                            weight_decay=weight_decay)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                                    milestones=lr_steps, \n",
    "                                                    gamma=lr_gamma)\n",
    "\n",
    "print(\"Start training\")\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    start_epoch = time.time()\n",
    "    train_one_epoch(\n",
    "        model, optimizer, data_loader, device, epoch, 20, writer, label_names\n",
    "    )\n",
    "    print(f\"Epoch time {time.time() - start_epoch}\")\n",
    "    writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if save_every_num_epochs and epoch % save_every_num_epochs == 0:\n",
    "        utils.save_on_master({\n",
    "            'model': model_without_ddp.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'lr_scheduler': lr_scheduler.state_dict(),\n",
    "            'args': args,\n",
    "            'label_names': label_names},\n",
    "            os.path.join(writer.log_dir, 'model_{}.pth'.format(epoch))\n",
    "        )\n",
    "\n",
    "    if epoch % evaluate_every_num_epochs == 0:\n",
    "        evaluate(\n",
    "            model, data_loader_test, epoch, writer, draw_threshold,\n",
    "            label_names, num_draw_predictions, device=device\n",
    "        )\n",
    "\n",
    "# Save after training is done\n",
    "utils.save_on_master({\n",
    "    'model': model_without_ddp.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'lr_scheduler': lr_scheduler.state_dict(),\n",
    "    'label_names': label_names},\n",
    "    os.path.join(writer.log_dir, 'model_finished.pth')\n",
    ")\n",
    "\n",
    "writer.close()\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print('Training time {}'.format(total_time_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12351), started 0:05:51 ago. (Use '!kill 12351' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-aae25d7b795ed48d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-aae25d7b795ed48d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir linc-detector-tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
