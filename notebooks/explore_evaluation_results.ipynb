{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore evaluation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "model_path = '../runs/ws_post/model_finished.pth'\n",
    "data_path = '../data/ws_cropped/'\n",
    "\n",
    "# Parameters\n",
    "device = 'cuda'\n",
    "batch_size = 1\n",
    "workers = 4\n",
    "draw_threshold = 0.5\n",
    "DPI = 220\n",
    "vert_size = 500\n",
    "line_width = 2\n",
    "draw_label = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebooks are stored in 'notebooks/' which breaks my imports\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import time\n",
    "from coco_utils import get_coco  # get_coco_kp\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import models.detection\n",
    "import transforms as T\n",
    "import torch\n",
    "import utils\n",
    "from matplotlib.pyplot import figure, imshow, show\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "convert_to_pil = torchvision.transforms.ToPILImage()\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "# Datasets\n",
    "dataset_train, num_classes, label_names = get_coco(data_path, image_set='train')\n",
    "dataset_test, _, _ = get_coco(data_path, image_set='val')\n",
    "\n",
    "# Samplers\n",
    "train_sampler = torch.utils.data.SequentialSampler(dataset_train)\n",
    "test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "train_batch_sampler = torch.utils.data.BatchSampler(\n",
    "    train_sampler, batch_size, drop_last=True)\n",
    "\n",
    "# Loaders\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_sampler=train_batch_sampler, num_workers=workers,\n",
    "    collate_fn=utils.collate_fn)\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1,\n",
    "    sampler=test_sampler, num_workers=workers,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "label_names = checkpoint['label_names']\n",
    "\n",
    "# Set up model\n",
    "model = models.detection.fasterrcnn_resnet50_fpn(\n",
    "    num_classes=len(label_names) + 1, pretrained_backbone=False\n",
    ")\n",
    "model.to(device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "print('Done loading model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.dpi'] = DPI\n",
    "\n",
    "def print_inference_results(data_loader, model):\n",
    "    images_evaluated = 0\n",
    "    for image, targets in data_loader:\n",
    "        pre_model_image = image[0]\n",
    "\n",
    "        image = list(img.to(device) for img in image)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # torch.cuda.synchronize()\n",
    "        model_time = time.time()\n",
    "        outputs = model(image)\n",
    "\n",
    "        outputs = [{k: v.to('cpu') for k, v in t.items()} for t in outputs]\n",
    "        model_time = time.time() - model_time\n",
    "\n",
    "\n",
    "        scores = outputs[0]['scores']\n",
    "        top_scores_filter = scores > draw_threshold\n",
    "        top_scores = scores[top_scores_filter]\n",
    "        top_boxes = outputs[0]['boxes'][top_scores_filter]\n",
    "        top_labels = outputs[0]['labels'][top_scores_filter]\n",
    "        image_with_boxes = utils.draw_boxes(\n",
    "            pre_model_image, top_boxes, top_labels, label_names, scores,\n",
    "            vert_size=vert_size, line_width=line_width, draw_label=draw_label\n",
    "        )\n",
    "        print(f\"# {images_evaluated}\")\n",
    "        print(label_names[top_labels - 1] if len(top_labels) > 1 else [label_names[top_labels - 1]])\n",
    "        figure()\n",
    "        imshow(np.asarray(convert_to_pil(image_with_boxes)))\n",
    "        show()\n",
    "        images_evaluated += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run data_loader_train or data_loader_test, but not both together or you will probably run out of GPU memory\n",
    "print_inference_results(data_loader_test, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
